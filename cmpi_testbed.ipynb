{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cartopy import config\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns equvalent to cdo fldmean\n",
    "def fldmean(ds):\n",
    "    weights = np.cos(np.deg2rad(ds.lat))\n",
    "    weights.name = \"weights\"\n",
    "    ds_weighted = ds.weighted(weights)\n",
    "    return ds.mean((\"lon\", \"lat\"))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose ERA5 or NCEP2. This switch also selects the eval/???? subfolders, so do not mix and match as this would lead to incorrect results.\n",
    "reanalysis='ERA5'\n",
    "\n",
    "#Define paths\n",
    "obs_path='obs/'\n",
    "model_path='//work/ollie/jstreffi/runtime/awicm3-frontiers/rprcon0.7/outdata/oifs/combined/'\n",
    "#model_path='/work/ollie/jstreffi/runtime/awicm3-frontiers/reference/outdata/oifs/combined/'\n",
    "#model_path='/work/ollie/jstreffi/runtime/awicm3-frontiers/precip_heat_flux_isolated/outdata/oifs/combined/'\n",
    "\n",
    "out_path='output/'\n",
    "eval_path='eval/'+reanalysis+'/'\n",
    "time = '198912-201411'\n",
    "\n",
    "'''\n",
    "Define model(s) and the respective variable dicts. (some models dont have the full set of variables available). \n",
    "I'd like to write this in a less verbose way, but it seems to involve conversion of string into variable \n",
    "via exec() locals() or globals(). I want that even less than long dict def.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "obs = { 'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis}\n",
    "\n",
    "models = {\n",
    "    'AWI-CM3_RPRCON_07':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "eval_models = {\n",
    "    'AWI-CM3_REF':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis}\n",
    "}\n",
    "\n",
    "\n",
    "#Define evaluation models\n",
    "eval_models = {\n",
    "    'ACCESS-ESM1-5':{\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'AWI-CM1-MR':{\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'AWI-ESM1-LR':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'BCC':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'CAMS':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'CAS-ESM2-0':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'CAN5':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'CESM2':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'CIESM':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'CMCC-CM2-SR5':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'CNRM6':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'E3SM-1-1':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'EC-Earth3':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'FGOALS-f3-L':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'FGOALS-g3':{\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'FIO2':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP'},\n",
    "    'GISS-E2-1-G':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'HadGEM3MM':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'HAMMOZ':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'INM5':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'IITM':{\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,},\n",
    "    'IPSL-CM6A-LR':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'KACE-1-0-G':{\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'KIOST-ESM':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'MCMUA1':{\n",
    "        'tas':reanalysis,\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'MIROC6':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'MPI-ESM1-2-LR':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'MRI':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'NESM3':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'NORESM2':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'NOAA-GFDL':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'SNU': {   \n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'TAIESM':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis},\n",
    "    'UKESM1-0-LL':{\n",
    "        'siconc':'OSISAF',\n",
    "        'tas':reanalysis,\n",
    "        'clt':'MODIS',\n",
    "        'pr':'GPCP',\n",
    "        'rlut':'CERES',\n",
    "        'uas':reanalysis,\n",
    "        'vas':reanalysis,\n",
    "        'ua':reanalysis,\n",
    "        'zg':reanalysis}\n",
    "}\n",
    "\n",
    "\n",
    "#Define regions\n",
    "regions={'glob' : {\n",
    "    'lat_min':-90,\n",
    "    'lat_max':90,},\n",
    "         \n",
    "    'arctic' : {\n",
    "    'lat_min':60,\n",
    "    'lat_max':90,},\n",
    "         \n",
    "    'northmid' : {\n",
    "    'lat_min':30,\n",
    "    'lat_max':60,},\n",
    "         \n",
    "    'tropics' : {\n",
    "    'lat_min':-30,\n",
    "    'lat_max':30,},\n",
    "         \n",
    "    'innertropics' : {\n",
    "    'lat_min':-15,\n",
    "    'lat_max':15,},\n",
    "         \n",
    "    'southmid' : {\n",
    "    'lat_min':-60,\n",
    "    'lat_max':-30,},\n",
    "         \n",
    "    'antarctic' : {\n",
    "    'lat_min':-90,\n",
    "    'lat_max':-60,}\n",
    "          \n",
    "}\n",
    "\n",
    "\n",
    "#Define seasons\n",
    "seasons = ['MAM', 'JJA', 'SON', 'DJF']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading obs/siconc_OSISAF_MAM.nc\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seas \u001b[38;5;129;01min\u001b[39;00m seasons:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mobs_path\u001b[38;5;241m+\u001b[39mvar\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mobs[var]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mseas\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     intermediate \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mseas\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     ds_obs[var,seas] \u001b[38;5;241m=\u001b[39m intermediate\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pyfesom2/lib/python3.10/site-packages/xarray/backends/api.py:495\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, backend_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    484\u001b[0m     decode_cf,\n\u001b[1;32m    485\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    491\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 495\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    502\u001b[0m     backend_ds,\n\u001b[1;32m    503\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    511\u001b[0m )\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pyfesom2/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:549\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    531\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    547\u001b[0m ):\n\u001b[0;32m--> 549\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m \u001b[43m_normalize_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     store \u001b[38;5;241m=\u001b[39m NetCDF4DataStore\u001b[38;5;241m.\u001b[39mopen(\n\u001b[1;32m    551\u001b[0m         filename_or_obj,\n\u001b[1;32m    552\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    559\u001b[0m         autoclose\u001b[38;5;241m=\u001b[39mautoclose,\n\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    562\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pyfesom2/lib/python3.10/site-packages/xarray/backends/common.py:26\u001b[0m, in \u001b[0;36m_normalize_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     23\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(path)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_uri(path):\n\u001b[0;32m---> 26\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpanduser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pyfesom2/lib/python3.10/posixpath.py:383\u001b[0m, in \u001b[0;36mabspath\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    381\u001b[0m         cwd \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwdb()\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m         cwd \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     path \u001b[38;5;241m=\u001b[39m join(cwd, path)\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m normpath(path)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "#Loading obs data\n",
    "ds_obs = OrderedDict()\n",
    "for var in obs:\n",
    "    for seas in seasons:\n",
    "        print('loading '+obs_path+var+'_'+obs[var]+'_'+seas+'.nc')\n",
    "\n",
    "        intermediate = xr.open_dataset(obs_path+var+'_'+obs[var]+'_'+seas+'.nc')\n",
    "        ds_obs[var,seas] = intermediate.compute()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Loading model data\n",
    "ds_model = OrderedDict()\n",
    "for model in models:\n",
    "    for var in models[model]:\n",
    "        for seas in seasons:\n",
    "            print('loading '+model_path+var+'_'+model+'_'+time+'_'+seas+'.nc')\n",
    "            intermediate = xr.open_dataset(model_path+var+'_'+model+'_'+time+'_'+seas+'.nc')\n",
    "            ds_model[var,seas,model] = intermediate.compute()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('siconc', 'MAM')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     filter2 \u001b[38;5;241m=\u001b[39m ds_model[var,seas,model]\u001b[38;5;241m.\u001b[39mdrop(timedim)\u001b[38;5;241m.\u001b[39mlat\u001b[38;5;241m<\u001b[39mregions[region][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat_max\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seas \u001b[38;5;129;01min\u001b[39;00m seasons:\n\u001b[1;32m     18\u001b[0m     abs_error[var,seas,model,region]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt((ds_model[var,seas,model]\u001b[38;5;241m.\u001b[39mdrop(timedim)\u001b[38;5;241m.\u001b[39mwhere(filter1 \u001b[38;5;241m&\u001b[39m filter2)\u001b[38;5;241m-\u001b[39m\n\u001b[0;32m---> 19\u001b[0m                                        \u001b[43mds_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseas\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mwhere(filter1 \u001b[38;5;241m&\u001b[39m filter2)\u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     20\u001b[0m                                       (ds_model[var,seas,model]\u001b[38;5;241m.\u001b[39mdrop(timedim)\u001b[38;5;241m.\u001b[39mwhere(filter1 \u001b[38;5;241m&\u001b[39m filter2)\u001b[38;5;241m-\u001b[39m\n\u001b[1;32m     21\u001b[0m                                        ds_obs[var,seas]\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mwhere(filter1 \u001b[38;5;241m&\u001b[39m filter2)))\n\u001b[1;32m     22\u001b[0m     mean_error[var,seas,model,region] \u001b[38;5;241m=\u001b[39m fldmean(abs_error[var,seas,model,region])\n",
      "\u001b[0;31mKeyError\u001b[0m: ('siconc', 'MAM')"
     ]
    }
   ],
   "source": [
    "#Calculate absolute error and build field mean of abs error\n",
    "abs_error = OrderedDict()\n",
    "mean_error = OrderedDict()\n",
    "timedim='time'\n",
    "for model in models:\n",
    "    for var in models[model]:\n",
    "        for region in regions:\n",
    "            if var == 'siconc' and (region != 'arctic' and region != 'antarctic'):\n",
    "                continue\n",
    "            try:\n",
    "                filter1 = ds_model[var,seas,model].drop(timedim).lat>regions[region]['lat_min']\n",
    "                filter2 = ds_model[var,seas,model].drop(timedim).lat<regions[region]['lat_max']\n",
    "\n",
    "            except:\n",
    "                timedim='time_counter'\n",
    "                filter1 = ds_model[var,seas,model].drop(timedim).lat>regions[region]['lat_min']\n",
    "                filter2 = ds_model[var,seas,model].drop(timedim).lat<regions[region]['lat_max']\n",
    "            for seas in seasons:\n",
    "                abs_error[var,seas,model,region]=np.sqrt((ds_model[var,seas,model].drop(timedim).where(filter1 & filter2)-\n",
    "                                                   ds_obs[var,seas].drop('time')).where(filter1 & filter2)*\n",
    "                                                  (ds_model[var,seas,model].drop(timedim).where(filter1 & filter2)-\n",
    "                                                   ds_obs[var,seas].drop('time').where(filter1 & filter2)))\n",
    "                mean_error[var,seas,model,region] = fldmean(abs_error[var,seas,model,region])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/abs/AWI-CM3_TCO319_DART.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Write field mean of errors into csv files\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabs/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m      4\u001b[0m         writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(csvfile, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m, quoting\u001b[38;5;241m=\u001b[39mcsv\u001b[38;5;241m.\u001b[39mQUOTE_MINIMAL)\n\u001b[1;32m      5\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeason\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbsMeanError\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/abs/AWI-CM3_TCO319_DART.csv'"
     ]
    }
   ],
   "source": [
    "#Write field mean of errors into csv files\n",
    "for model in models:\n",
    "    with open(out_path+'abs/'+model+'.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=' ',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(['Variable','Region','Season','AbsMeanError'])\n",
    "        for var in models[model]:\n",
    "            for region in regions:\n",
    "                if var == 'siconc' and (region != 'arctic' and region != 'antarctic'):\n",
    "                    continue\n",
    "                for seas in seasons:\n",
    "                    if (var == 'tas'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(mean_error[var,seas,model,region].tas.values[0])])\n",
    "                    if (var == 'uas'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(mean_error[var,seas,model,region].uas.values[0])])\n",
    "                    if (var == 'vas'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(mean_error[var,seas,model,region].vas.values[0])])\n",
    "                    if (var == 'ua'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(mean_error[var,seas,model,region].ua.values[0])])\n",
    "                    if (var == 'zg'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(mean_error[var,seas,model,region].zg.values[0])])\n",
    "                    if (var == 'pr'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(mean_error[var,seas,model,region].pr.values[0])])\n",
    "                    if (var == 'rlut'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(mean_error[var,seas,model,region].rlut.values[0])])\n",
    "                    if (var == 'clt'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(mean_error[var,seas,model,region].clt.values[0])])\n",
    "                    if (var == 'siconc'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(mean_error[var,seas,model,region].siconc.values[0])])"
   ]
  },
  {
   "cell_type": "code",
     ]
    }
   ],
   "source": [
    "#Read precalculated cmip6 field mean of errors from csv files\n",
    "collect = np.empty([len(eval_models),len(obs),len(regions),len(seasons)])*np.nan\n",
    "i=0\n",
    "for eval_model in eval_models:\n",
    "    df = pd.read_csv(eval_path+eval_model+'.csv', delimiter=' ')\n",
    "    values = df['AbsMeanError'] #you can also use df['column_name']\n",
    "    j=0\n",
    "    r=0\n",
    "    for var in obs:\n",
    "        k=0\n",
    "        a=(df['Variable']==var).to_list()\n",
    "        if any(a): # Check if variable appears in list. If not, skip it.\n",
    "            print('reading',eval_model,var)\n",
    "            pass\n",
    "        else:\n",
    "            j+=1\n",
    "            print('skipping',eval_model,var)\n",
    "            continue\n",
    "        for region in regions:\n",
    "            l=0\n",
    "            if var == 'siconc' and (region != 'arctic' and region != 'antarctic'):\n",
    "                continue\n",
    "            for seas in seasons:\n",
    "                collect[i,j,k,l]=values[r]\n",
    "                l+=1\n",
    "                r+=1\n",
    "            k+=1\n",
    "        j+=1\n",
    "    i+=1\n",
    "ensmean=np.nanmean(collect,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place sums of error into easier to inspect dictionary\n",
    "eval_error_mean = OrderedDict()\n",
    "j=0\n",
    "for var in obs:\n",
    "    k=0\n",
    "    for region in regions:\n",
    "        l=0\n",
    "        if var == 'siconc' and (region != 'arctic' and region != 'antarctic'):\n",
    "            continue\n",
    "        for seas in seasons:\n",
    "            eval_error_mean[var,region,seas]=ensmean[j,k,l]\n",
    "            l+=1\n",
    "        k+=1\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate ratio of current model error to evaluation model error\n",
    "error_fraction = OrderedDict()\n",
    "sum=0\n",
    "for model in models:\n",
    "    for var in models[model]:\n",
    "        for region in regions:\n",
    "            if var == 'siconc' and (region != 'arctic' and region != 'antarctic'):\n",
    "                continue\n",
    "            for seas in seasons:\n",
    "                error_fraction[var,seas,model,region] = mean_error[var,seas,model,region] / eval_error_mean[var,region,seas]\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write ratio of field mean of errors into csv files and sum up error fractions for cmpi score\n",
    "#TODO beautification: find way to access error_fraction[var,seas,model,region].var.values[0] to make\n",
    "#one call out of nine\n",
    "cmpi = OrderedDict()\n",
    "for model in models:\n",
    "    sum=0\n",
    "    iter=0\n",
    "    with open(out_path+'frac/'+model+'_fraction.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=' ',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(['Variable','Region','Season','FracMeanError'])\n",
    "        for var in models[model]:\n",
    "            for region in regions:\n",
    "                if var == 'siconc' and (region != 'arctic' and region != 'antarctic'):\n",
    "                    continue\n",
    "                for seas in seasons:\n",
    "                    if (var == 'tas'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(error_fraction[var,seas,model,region].tas.values[0])])\n",
    "                        sum+=error_fraction[var,seas,model,region].tas.values[0]\n",
    "                    if (var == 'uas'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(error_fraction[var,seas,model,region].uas.values[0])])\n",
    "                        sum+=error_fraction[var,seas,model,region].uas.values[0]\n",
    "                    if (var == 'vas'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(error_fraction[var,seas,model,region].vas.values[0])])\n",
    "                        sum+=error_fraction[var,seas,model,region].vas.values[0]\n",
    "                    if (var == 'ua'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(error_fraction[var,seas,model,region].ua.values[0])])\n",
    "                        sum+=error_fraction[var,seas,model,region].ua.values[0][0]\n",
    "                    if (var == 'zg'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(error_fraction[var,seas,model,region].zg.values[0])])\n",
    "                        sum+=error_fraction[var,seas,model,region].zg.values[0][0]\n",
    "                    if (var == 'pr'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(error_fraction[var,seas,model,region].pr.values[0])])\n",
    "                        sum+=error_fraction[var,seas,model,region].pr.values[0]\n",
    "                    if (var == 'rlut'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(error_fraction[var,seas,model,region].rlut.values[0])])\n",
    "                        sum+=error_fraction[var,seas,model,region].rlut.values[0]\n",
    "                    if (var == 'clt'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(error_fraction[var,seas,model,region].clt.values[0])])\n",
    "                        sum+=error_fraction[var,seas,model,region].clt.values[0]\n",
    "                    if (var == 'siconc'):\n",
    "                        writer.writerow([var,region,seas,np.squeeze(error_fraction[var,seas,model,region].siconc.values[0])])\n",
    "                        sum+=error_fraction[var,seas,model,region].siconc.values[0]\n",
    "                    iter+=1\n",
    "        cmpi[model]=np.squeeze(sum)/iter\n",
    "        writer.writerow(['CMPI','global','yearly',cmpi[model]])"
   ]
  },
  {
   "cell_type": "code",
    }
   ],
   "source": [
    "#Read precalculated evaluation field means of errors from csv files and plot heatmap\n",
    "collect_frac = np.empty([len(models),len(obs),len(regions),len(seasons)])*np.nan\n",
    "i=0\n",
    "for model in models:\n",
    "    df = pd.read_csv(out_path+'frac/'+model+'_fraction.csv', delimiter=' ')\n",
    "    values = df['FracMeanError'] #you can also use df['column_name']\n",
    "    j=0\n",
    "    r=0\n",
    "    for var in obs:\n",
    "        k=0\n",
    "        a=(df['Variable']==var).to_list()\n",
    "        if any(a): # Check if variable appears in list. If not, skip it.\n",
    "            print('reading',model,var)\n",
    "            pass\n",
    "        else:\n",
    "            j+=1\n",
    "            print('skipping',model,var)\n",
    "            continue\n",
    "        for region in regions:\n",
    "            l=0 # Check if combination of variable and region appears in list. If not, skip it.\n",
    "            if np.max(np.add(list(map(int, (df['Variable']==var).to_list())),list(map(int, (df['Region']==region).to_list())))) ==2:\n",
    "                pass\n",
    "            else:\n",
    "                k+=1\n",
    "                continue\n",
    "            for seas in seasons:\n",
    "                collect_frac[i,j,k,l]=values[r]\n",
    "                l+=1\n",
    "                r+=1\n",
    "            k+=1\n",
    "        j+=1\n",
    "    collect_frac_reshaped = collect_frac[i,:,:,:].reshape(len(obs),len(regions)*len(seasons))\n",
    "    #collect_frac_reshaped = collect_frac[i,:,:,:].reshape(j,k*l)\n",
    "\n",
    "    seasons_plot = [' MAM', ' JJA', ' SON', ' DJF'] #adding spaces in front\n",
    "    a=seasons_plot*len(regions)\n",
    "    b=np.repeat(list(regions.keys()),len(seasons_plot))\n",
    "    coord=[n+str(m) for m,n in zip(a,b)]\n",
    "    collect_frac_dataframe = pd.DataFrame(data=collect_frac_reshaped, index=obs, columns=coord)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(len(coord)/1.5,len(obs)/1.5))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.rcParams['axes.facecolor'] = 'white'\n",
    "    ax = sns.heatmap(collect_frac_dataframe, vmin=0.5, vmax=1.5,center=1,annot=True,fmt='.2f',cmap=\"PiYG_r\",cbar=False,linewidths=1)\n",
    "    plt.xticks(rotation=90,fontsize=14)\n",
    "    plt.yticks(rotation=0, ha='right',fontsize=14)\n",
    "    plt.title(model+' CMPI: '+str(round(cmpi[model],3)), fontsize=18)\n",
    "    \n",
    "    plt.savefig(out_path+'plot/'+model+'.png',dpi=150,bbox_inches='tight')\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
